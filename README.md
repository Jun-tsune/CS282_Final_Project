# CS282-Fall2025 Final Project

This is the repository for the final project of CS282-Fall2025.

This project studies how compressive memory affects In-Context Learning (ICL) in longsequence Transformers. Using synthetic tasks, we compare standard and Compressive Transformers across context lengths and memory ratios. We expect compressive memory to enhance long-range ICL while showing diminishing gains as compression increases.